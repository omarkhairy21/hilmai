# Pinecone-Only Setup Guide

## Architecture Decision

**We use Pinecone for vector storage only** - no pgvector in Supabase needed!

### Why This Approach?

**Supabase (PostgreSQL):**
- âœ… Stores complete transaction data (amount, merchant, category, date, etc.)
- âœ… Source of truth for all transaction details
- âœ… Fast lookups by ID

**Pinecone:**
- âœ… Stores embeddings (3072-dimensional vectors)
- âœ… Optimized for semantic search
- âœ… Lightweight metadata for filtering
- âœ… Scales to millions of vectors

### Data Flow

```
Transaction Input
     â†“
Generate Embedding (OpenAI)
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Supabase     â”‚   Pinecone     â”‚
â”‚  (Main Data)   â”‚  (Embeddings)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ID           â”‚ â€¢ ID (same)    â”‚
â”‚ â€¢ Amount       â”‚ â€¢ Embedding    â”‚
â”‚ â€¢ Merchant     â”‚ â€¢ Metadata:    â”‚
â”‚ â€¢ Category     â”‚   - user_id    â”‚
â”‚ â€¢ Date         â”‚   - category   â”‚
â”‚ â€¢ Description  â”‚   - merchant   â”‚
â”‚ â€¢ User ID      â”‚   - date       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Search Flow

```
User Query: "coffee purchases"
     â†“
Generate Query Embedding
     â†“
Search Pinecone (similarity search)
     â†“
Get matching transaction IDs
     â†“
Fetch full details from Supabase
     â†“
Return complete transaction data
```

## Setup Instructions

### 1. Create Pinecone Account

1. Go to [pinecone.io](https://www.pinecone.io/)
2. Sign up (free tier available)
3. Create a new index:
   - **Index Name:** `hilm-transactions`
   - **Dimensions:** `3072`
   - **Metric:** `cosine`
   - **Pod Type:** `Starter` (free)

### 2. Get API Key

1. In Pinecone dashboard, go to "API Keys"
2. Copy your API key

### 3. Update Environment Variables

Add to `/Users/omar/Desktop/hilm.ai/agent/.env`:

```bash
# Pinecone Configuration
PINECONE_API_KEY=pc-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
PINECONE_INDEX=hilm-transactions
```

### 4. That's It!

No SQL migrations needed! Your Supabase `transactions` table already has all the columns it needs.

## What Gets Stored Where

### Supabase `transactions` Table

```sql
CREATE TABLE transactions (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users(id),
  telegram_chat_id BIGINT,
  amount NUMERIC,
  currency TEXT,
  merchant TEXT,
  category TEXT,
  description TEXT,
  transaction_date TIMESTAMP,
  created_at TIMESTAMP DEFAULT NOW()
);
```

**No embedding column needed!**

### Pinecone Index

```typescript
{
  id: "transaction-uuid",
  values: [0.023, -0.015, ...], // 3072 dimensions
  metadata: {
    user_id: "user-uuid",
    telegram_chat_id: 123456789,
    amount: 25.50,
    currency: "USD",
    merchant: "Starbucks",
    category: "dining",
    date: "2025-01-15T10:00:00.000Z",
    description: "Morning coffee"
  }
}
```

## Testing

### Quick Test

```bash
cd /Users/omar/Desktop/hilm.ai/agent
npx tsx --env-file=.env quick-test.ts
```

Should show:
```
âœ… Pinecone connection successful
âœ… Embedding generation works
Dimension: 3072 âœ“
```

### Full Test

1. **Start bot:**
   ```bash
   npm run bot:dev
   ```

2. **Send transaction:**
   "Spent $5 on coffee at Starbucks"

3. **Check logs:**
   ```
   âœ… Embedding stored in Pinecone for transaction abc-123
   ```

4. **Ask question:**
   "How much did I spend on coffee?"

5. **Should work!** ğŸ‰

## Troubleshooting

### "Pinecone connection failed"
- Check `PINECONE_API_KEY` in `.env`
- Ensure no extra spaces around the key
- Verify index name matches exactly: `hilm-transactions`

### "Dimension mismatch"
- Pinecone index must be 3072 dimensions
- Delete and recreate index if wrong

### "No results found"
- Make sure transactions have been saved with embeddings
- Check Pinecone dashboard â†’ Index stats â†’ Vector count

### "Metadata not returned"
- Ensure `includeMetadata: true` in search query (already set in code)

## Performance

- **Embedding generation:** ~200-500ms
- **Pinecone upsert:** ~50-100ms
- **Pinecone search:** ~50-100ms
- **Supabase fetch:** ~20-50ms
- **Total query time:** ~1-2 seconds

## Costs

### Pinecone Free Tier
- âœ… 100,000 vectors
- âœ… 1 index
- âœ… Unlimited queries
- âœ… Perfect for MVP/development

### OpenAI Embeddings
- ğŸ’° $0.00013 per 1K tokens
- ~$0.0001 per transaction
- 10,000 transactions = ~$1

### Supabase
- âœ… Free tier (500MB database)
- âœ… Plenty for transaction storage

## Advantages of This Approach

1. âœ… **Simpler setup** - No pgvector extension needed
2. âœ… **Better performance** - Pinecone optimized for vector search
3. âœ… **Easier scaling** - Pinecone handles millions of vectors
4. âœ… **Separation of concerns** - Transactions in SQL, vectors in Pinecone
5. âœ… **No data duplication** - Embeddings only in one place
6. âœ… **Lower costs** - No extra storage in Supabase

## Migration Notes

If you previously ran `add_embeddings.sql`, you can safely ignore the `embedding` column in Supabase. It won't be used.

To remove it (optional):
```sql
ALTER TABLE transactions DROP COLUMN IF EXISTS embedding;
```

But it's fine to leave it - just won't be populated.

## What Changed

### Before (Dual Storage)
```typescript
// Save to Supabase WITH embedding
await db.from('transactions').insert({
  ...transaction,
  embedding: `[${embedding.join(',')}]`  // âŒ Removed
});

// Also save to Pinecone
await pinecone.upsert([...]);
```

### After (Pinecone Only)
```typescript
// Save to Supabase WITHOUT embedding
await db.from('transactions').insert({
  ...transaction
  // No embedding column âœ…
});

// Save embedding to Pinecone only
await pinecone.upsert([{
  id,
  values: embedding,
  metadata: {...}
}]);
```

## Files Modified

1. âœ… `src/mastra/tools/save-transaction-tool.ts` - Removed embedding column
2. âœ… `src/mastra/tools/search-transactions-tool.ts` - Added clarifying comments
3. âœ… `add_embeddings.sql` â†’ Archived (not needed)

## Ready to Use!

Just:
1. âœ… Create Pinecone index
2. âœ… Add API key to `.env`
3. âœ… Start bot
4. âœ… Test with transactions and queries

No database migrations required! ğŸš€
